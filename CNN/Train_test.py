# -*- coding: utf-8 -*-
"""Untitled3.ipynb의 사본

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ss3pqkDmu4mP0yetqPZGTMMFp19RC1AU
"""

import torch
import torchvision
from torchvision import datasets, models, transforms
import torchvision.transforms as transforms
from torch.utils.data import DataLoader, Dataset, TensorDataset
from torch.utils.data.dataset import random_split

import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim

from torchsummary import summary as summary_
import numpy as np
import matplotlib.pyplot as plt

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

# 기본적인 파라미터 설정
batch_size = 128
max_pool_kernel = 2
learning_rate = 0.0005
num_epochs = 30
num_classes = 10

datasets = torchvision.datasets.CIFAR10(root='./datasets',
                                        train=True,
                                        transform=transforms.ToTensor(),
                                        download=True)

train_dataset, val_dataset = random_split(datasets, [40000,10000])

test_dataset = torchvision.datasets.CIFAR10(root='./datasets',
                                       train=False,
                                       transform=transforms.ToTensor())

train_loader = DataLoader(dataset=train_dataset,
                        batch_size = batch_size, 
                        shuffle = True)
val_loader = DataLoader(dataset=val_dataset, 
                      batch_size = batch_size,
                      shuffle = False)
test_loader = DataLoader(dataset=test_dataset,
                         batch_size=batch_size,
                         shuffle=False)

class ConvNet(nn.Module):
  def __init__(self, num_classes=10):
    super(ConvNet, self).__init__()
    self.layer1 = nn.Sequential(
        nn.Conv2d(3, 6, 5, stride=1, padding = 2, padding_mode = 'reflect'), #input : batch_size = 128, 3 channel, 32x32 pixel
        nn.BatchNorm2d(6),
        nn.ReLU(),
        nn.MaxPool2d(kernel_size=2, stride=2) # output : batch_size = 128, 6 channel, 16x16 pixel
    )
    self.layer2 = nn.Sequential(
        nn.Conv2d(6, 16, 3, stride=1, padding=1), # input : batch_size = 128, 6 channel, 16x16 pixel
        nn.BatchNorm2d(16),
        nn.ReLU(),
        nn.MaxPool2d(kernel_size=2, stride=2) # ouput : batch_size = 128, 16 channel, 8x8 pixel
    )
    self.layer3 = nn.Sequential(
        nn.Conv2d(16, 32, 3, stride=1, padding=1), # input : batch_size = 128, 16 channel, 8X8 pixel
        nn.BatchNorm2d(32),
        nn.ReLU(),
        nn.MaxPool2d(kernel_size=2, stride=2) # output : batch_size = 128, 32 channel, 4x4 pixel
    )
    self.fc1 = nn.Linear(512, 120) # input : 32 x 4 x 4 = 512
    self.fc2 = nn.Linear(120, 80)
    self.fc3 = nn.Linear(80, num_classes)

  def forward(self, x):
    x = self.layer1(x)
    x = self.layer2(x)
    x = self.layer3(x)
    
    x = x.reshape(x.size(0),-1)
    x = F.relu(self.fc1(x))
    x = F.relu(self.fc2(x))
    x = F.softmax(self.fc3(x))
    return x

model = ConvNet(num_classes).to(device)

print("                model summary(print output shape)")
summary_(model,(3,32,32),batch_size=batch_size)

criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)

total_step = len(train_loader)
train_loss_list = [] 
train_loss_value = 0
val_loss_list = []
val_loss_value = 0
test_loss_list = [] 
test_loss_value = 0


train_acc_list = []
train_acc_value = 0
val_acc_list = []
val_acc_value = 0
test_acc_list = [] 
test_acc_value = 0

# Train
for epoch in range(num_epochs):
  correct = 0
  for i, (images, labels) in enumerate(train_loader):

    # Assign Tensors to Configured Device
    images = images.to(device)
    labels = labels.to(device)

    # Forward Propagation
    outputs = model(images)

    # Get Loss, Compute Gradient, Update Parameters
    loss_value = criterion(outputs, labels)
    train_loss_value += loss_value.item()
    optimizer.zero_grad()
    loss_value.backward()
    optimizer.step()

    # evaluate loss and accuracy of train data set
    _, predicted = torch.max(outputs, 1)
    correct += (predicted == labels).sum().item()

  train_acc_value = correct / (len(train_loader) * batch_size) * 100
  train_loss_value = train_loss_value / len(train_loader)
  train_acc_list.append(train_acc_value)
  train_loss_list.append(train_loss_value) 
  
  # Print Loss for Tracking Training
  print('\n')
  print('Completed training Epoch', epoch + 1, 
        '\nTraining Accuracy: %.2f%%' %(train_acc_value),
        '\nTraining Loss: %.4f' %train_loss_value)
  
  with torch.no_grad(): 
    model.eval() 
    correct = 0
    for images, labels in val_loader:

      images = images.to(device)
      labels = labels.to(device)
      predicted_val_outputs = model(images) 
      val_loss_value += criterion(predicted_val_outputs, labels).item()
      _, val_predicted = torch.max(predicted_val_outputs, 1)
      correct += (val_predicted == labels).sum().item()
    
    val_acc_value = (correct/(len(val_loader) * batch_size)*100)
    val_acc_list.append(val_acc_value)
    val_loss_value = val_loss_value/len(val_loader)
    val_loss_list.append(val_loss_value)

    print('validation accuracy: {:.2f}%\nvalidation loss: {:.4f}'.format(val_acc_value, val_loss_value,))
    print('\n')
    print("=" * 35)

  with torch.no_grad(): 
    model.eval() 
    correct = 0
    for images, labels in test_loader:

      images = images.to(device)
      labels = labels.to(device)
      predicted_test_outputs = model(images) 
      test_loss_value += criterion(predicted_test_outputs, labels).item()
      _, test_predicted = torch.max(predicted_test_outputs, 1)
      correct += (test_predicted == labels).sum().item()
    
    test_acc_value = (correct/(len(test_loader) * batch_size)*100)
    test_acc_list.append(test_acc_value)
    test_loss_value = test_loss_value/len(test_loader)
    test_loss_list.append(test_loss_value)
    
  if epoch+1 == num_epochs:
    torch.save(model.state_dict(), 'model.pth')
  else:
    torch.save(model.state_dict(), 'model-{:02d}_epochs.pth'.format(epoch+1))

## plot accuracy curve
acc_plot = plt.figure(figsize=(15,9))
acc_plot = plt.plot(train_acc_list, label = 'train')
acc_plot = plt.plot(val_acc_list, label = 'val')
acc_plot = plt.plot(test_acc_list, label = 'test')

acc_plot = plt.title('accuracy curve')
acc_plot = plt.xlabel('accuracy (%)')
acc_plot = plt.ylabel('Epoch')

acc_plot = plt.legend(loc='best')

plt.show(acc_plot)

## plot loss curve
loss_plot = plt.figure(figsize=(15,9))
loss_plot = plt.plot(train_loss_list, label = 'train')
loss_plot = plt.plot(val_loss_list, label = 'val')
loss_plot = plt.plot(test_loss_list, label = 'test')

loss_plot = plt.title('loss curve')
loss_plot = plt.xlabel('loss')
loss_plot = plt.ylabel('Epoch')

loss_plot = plt.legend(loc='best')
plt.show(acc_plot)

test_model = ConvNet().to(device)

test_model.load_state_dict(torch.load('/Desktop/model.pth'))
test_model.eval()

correct = 0
with torch.no_grad(): # auto_grad off
  for images, labels in test_loader:
    images = images.to(device)
    labels = labels.to(device)
    outputs = test_model(images)
    _, predicted = torch.max(outputs.data, 1)
 
    correct += (predicted == labels).sum().item()

  print('Accuracy of the network on the {} test images {:.2f}%'.format(len(test_loader)*batch_size, 100*correct/(len(test_loader) * batch_size)))